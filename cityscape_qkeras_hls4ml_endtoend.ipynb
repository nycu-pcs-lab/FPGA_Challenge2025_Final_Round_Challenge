{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b05eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qkeras\n",
    "!pip install tensorflow==2.12.0 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 20\n",
    "\n",
    "train_data = np.load(f\"/kaggle/input/fpga-challenge-final-round/cityscapes_train_size(64 64).npz\")\n",
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "\n",
    "x_test = np.load(f\"/kaggle/input/fpga-challenge-final-round/test_images_size(64 64).npy\")\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aaae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample visualization to verify extracted data\n",
    "sample_idx = 0\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Show original image\n",
    "axes[0].imshow(x_train[sample_idx])\n",
    "axes[0].set_title(f\"Extracted Image\\nShape: {x_train[sample_idx].shape}\\nRange: [{x_train[sample_idx].min():.3f}, {x_train[sample_idx].max():.3f}]\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Show mask \n",
    "axes[1].imshow(y_train[sample_idx], cmap='tab20', vmin=0, vmax=n_classes-1)\n",
    "axes[1].set_title(f\"Extracted Mask\\nShape: {y_train[sample_idx].shape}\\nRange: [{y_train[sample_idx].min()}, {y_train[sample_idx].max()}]\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sample validation:\")\n",
    "print(f\"  Image shape: {x_train[sample_idx].shape} (should be H, W, 3)\")\n",
    "print(f\"  Mask shape: {y_train[sample_idx].shape} (should be H, W)\")\n",
    "print(f\"  Image dtype: {x_train[sample_idx].dtype} (should be float32)\")\n",
    "print(f\"  Mask dtype: {y_train[sample_idx].dtype} (should be int32)\")\n",
    "print(f\"  Unique classes in sample: {np.unique(y_train[sample_idx])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data into train and validation sets (80:20 split)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42, stratify=y_train.reshape(len(y_train), -1)[:, 0]\n",
    ")\n",
    "\n",
    "print(f\"Train set: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {x_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476e243",
   "metadata": {},
   "source": [
    "# build qkeras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab50dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_qkeras_unet_vgg(input_shape=(32, 64, 3), n_classes=20):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    def vgg_qconv_block(x, filters, n_convs=2, activation='quantized_relu(6)',\n",
    "                        kernel_quantizer='quantized_bits(6,0,alpha=1)',\n",
    "                        bias_quantizer='quantized_bits(6,0,alpha=1)'):\n",
    "        for _ in range(n_convs):\n",
    "            x = QConv2DBatchnorm(\n",
    "                filters=filters,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                kernel_quantizer=kernel_quantizer,\n",
    "                bias_quantizer=bias_quantizer,\n",
    "                use_bias=True\n",
    "            )(x)\n",
    "            x = QActivation(activation)(x)\n",
    "        return x\n",
    "\n",
    "    # === ENCODER ===\n",
    "    e1 = vgg_qconv_block(inputs, 16, n_convs=2)\n",
    "    p1 = MaxPooling2D(pool_size=(2, 2))(e1)\n",
    "\n",
    "    e2 = vgg_qconv_block(p1, 32, n_convs=2)\n",
    "    p2 = MaxPooling2D(pool_size=(2, 2))(e2)\n",
    "\n",
    "    e3 = vgg_qconv_block(p2, 64, n_convs=2)\n",
    "\n",
    "    # === DECODER ===\n",
    "    d2 = UpSampling2D(size=(2, 2))(e3)\n",
    "    d2 = Concatenate()([d2, e2])\n",
    "    d2 = vgg_qconv_block(d2, 32, n_convs=2)\n",
    "\n",
    "    d1 = UpSampling2D(size=(2, 2))(d2)\n",
    "    d1 = Concatenate()([d1, e1])\n",
    "    d1 = vgg_qconv_block(d1, 16, n_convs=2)\n",
    "\n",
    "    # === OUTPUT ===\n",
    "    outputs = QConv2D(\n",
    "        filters=n_classes,\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        activation=None,\n",
    "        kernel_quantizer='quantized_bits(6,0,alpha=1)',\n",
    "        bias_quantizer='quantized_bits(6,0,alpha=1)',\n",
    "        use_bias=True\n",
    "    )(d1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb449ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_qkeras_unet_vgg(input_shape=(64, 64, 3), n_classes=n_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf9576",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "class IoUCallback(Callback):\n",
    "\n",
    "    def __init__(self, x_val, y_val, num_classes, batch_size=16, frequency=1):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.frequency = frequency  # Calculate IoU every N epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Only calculate IoU every N epochs to save time\n",
    "        if (epoch + 1) % self.frequency != 0:\n",
    "            return\n",
    "            \n",
    "        # === Batch prediction to avoid memory issues ===\n",
    "        y_pred_list = []\n",
    "        for i in range(0, len(self.x_val), self.batch_size):\n",
    "            batch_x = self.x_val[i:i+self.batch_size]\n",
    "            pred = self.model.predict(batch_x, verbose=0)\n",
    "            # Convert logits to class predictions\n",
    "            pred_classes = np.argmax(pred, axis=-1)\n",
    "            y_pred_list.append(pred_classes)\n",
    "        \n",
    "        y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "        y_true = self.y_val\n",
    "\n",
    "        # === Calculate IoU for each class ===\n",
    "        ious = []\n",
    "        class_counts = []\n",
    "        \n",
    "        for cls in range(self.num_classes):\n",
    "            # Get binary masks for this class\n",
    "            pred_mask = (y_pred == cls).astype(np.uint8)\n",
    "            true_mask = (y_true == cls).astype(np.uint8)\n",
    "            \n",
    "            # Count pixels of this class in ground truth\n",
    "            true_pixels = np.sum(true_mask)\n",
    "            class_counts.append(true_pixels)\n",
    "            \n",
    "            # Skip classes that don't appear in ground truth\n",
    "            if true_pixels == 0:\n",
    "                if np.sum(pred_mask) == 0:\n",
    "                    # Both prediction and ground truth have no pixels of this class\n",
    "                    ious.append(1.0)  # Perfect IoU for absent class\n",
    "                else:\n",
    "                    # False positives for this class\n",
    "                    ious.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Calculate IoU using sklearn (handles edge cases)\n",
    "            iou = jaccard_score(\n",
    "                true_mask.ravel(), \n",
    "                pred_mask.ravel(), \n",
    "                average='binary',\n",
    "                zero_division=0.0  # Handle division by zero\n",
    "            )\n",
    "            ious.append(iou)\n",
    "\n",
    "        # === Calculate metrics ===\n",
    "        mean_iou = np.mean(ious)\n",
    "        \n",
    "        # Calculate weighted IoU (weighted by class frequency)\n",
    "        total_pixels = np.sum(class_counts)\n",
    "        if total_pixels > 0:\n",
    "            weights = np.array(class_counts) / total_pixels\n",
    "            weighted_iou = np.average(ious, weights=weights)\n",
    "        else:\n",
    "            weighted_iou = mean_iou\n",
    "\n",
    "        # === Log results ===\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        \n",
    "        logs['val_mean_iou'] = mean_iou\n",
    "        logs['val_weighted_iou'] = weighted_iou\n",
    "        \n",
    "        print(f\" â€” val_mean_IoU: {mean_iou:.4f} | val_weighted_IoU: {weighted_iou:.4f}\")\n",
    "        \n",
    "        # Optionally print per-class IoU for debugging\n",
    "        if (epoch + 1) % (self.frequency * 5) == 0:  # Every 5th IoU calculation\n",
    "            print(\"Per-class IoU:\")\n",
    "            for cls in range(min(10, self.num_classes)):  # Show first 10 classes\n",
    "                print(f\"  Class {cls}: {ious[cls]:.3f} ({class_counts[cls]} pixels)\")\n",
    "\n",
    "# Create the IoU callback\n",
    "iou_callback = IoUCallback(\n",
    "    x_val=x_val, \n",
    "    y_val=y_val, \n",
    "    num_classes=n_classes, \n",
    "    batch_size=32,\n",
    "    frequency=1  # Calculate every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOSS FUNCTIONS FOR SEGMENTATION ===\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Dice Loss for segmentation (works with sparse labels)\n",
    "    y_true: (batch, H, W) - integer class labels\n",
    "    y_pred: (batch, H, W, num_classes) - logits/probabilities\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities\n",
    "    y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "    \n",
    "    # Convert sparse labels to one-hot\n",
    "    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
    "    \n",
    "    # Flatten for computation\n",
    "    y_true_flat = tf.reshape(y_true_one_hot, [-1, tf.shape(y_pred)[-1]])\n",
    "    y_pred_flat = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "    \n",
    "    # Dice coefficient for each class\n",
    "    intersection = tf.reduce_sum(y_true_flat * y_pred_flat, axis=0)\n",
    "    union = tf.reduce_sum(y_true_flat, axis=0) + tf.reduce_sum(y_pred_flat, axis=0)\n",
    "    \n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    # Return 1 - mean dice as loss\n",
    "    return 1.0 - tf.reduce_mean(dice)\n",
    "\n",
    "def combined_loss(y_true, y_pred, dice_weight=0.7, ce_weight=0.3):\n",
    "    \"\"\"\n",
    "    Combined Dice + Cross-Entropy Loss\n",
    "    Often works better than either alone\n",
    "    \"\"\"\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    ce = SparseCategoricalCrossentropy(from_logits=True)(y_true, y_pred)\n",
    "    return dice_weight * dice + ce_weight * ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456601e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=combined_loss,\n",
    "    metrics=[SparseCategoricalAccuracy(name='accuracy')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81067f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    iou_callback  # Only IoU monitoring for validation metrics\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20, \n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Vuisualize predictions\n",
    "def visualize_predictions(model, x_val, y_val, num_samples=5):\n",
    "    indices = np.random.choice(len(x_val), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, num_samples * 4))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = x_val[idx]\n",
    "        true_mask = y_val[idx]\n",
    "        \n",
    "        # Predict mask\n",
    "        pred_logits = model.predict(np.expand_dims(img, axis=0))\n",
    "        pred_mask = np.argmax(pred_logits, axis=-1)[0]\n",
    "        \n",
    "        # Plot original image\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title(\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Plot true mask\n",
    "        axes[i, 1].imshow(true_mask, cmap='tab20', vmin=0, vmax=n_classes-1)\n",
    "        axes[i, 1].set_title(\"True Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Plot predicted mask\n",
    "        axes[i, 2].imshow(pred_mask, cmap='tab20', vmin=0, vmax=n_classes-1)\n",
    "        axes[i, 2].set_title(\"Predicted Mask\")\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, x_val, y_val, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bcef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "model.evaluate(x_val, y_val, verbose=1)\n",
    "\n",
    "# evaluate on mIoU (mean Intersection over Union)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_logits = model.predict(x_val, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred_logits, axis=-1)\n",
    "\n",
    "# Flatten for sklearn\n",
    "y_true_flat = y_val.flatten()\n",
    "y_pred_flat = y_pred_classes.flatten()\n",
    "\n",
    "# Compute mean IoU over all classes\n",
    "miou = jaccard_score(y_true_flat, y_pred_flat, average='macro', labels=np.arange(n_classes), zero_division=0)\n",
    "print(f\"Validation mIoU (sklearn): {miou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf9d3b",
   "metadata": {},
   "source": [
    "# hls4ml conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f89336",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hls4ml==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(model, \n",
    "                                              granularity='name', \n",
    "                                              backend='Vitis',\n",
    "                                              default_precision='fixed<32,16>', \n",
    "                                              default_reuse_factor=16384,                                             \n",
    "                                             )\n",
    "config['Model']['Strategy'] = 'Resource'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_path = \"cityscape_hls_project\"\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=config,\n",
    "    output_dir=hls_path,\n",
    "    backend = \"Vitis\",\n",
    "    clock_period=5,\n",
    "    io_type = \"io_stream\", # default is \"io_parallel\"\n",
    "    part='xcu55c-fsvh2892-2L-e', # U55C FPGA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0dcf03",
   "metadata": {},
   "source": [
    "# HLS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "hls_pred_classes_all = []\n",
    "hls_pred_all = []\n",
    "for data in tqdm(x_test):\n",
    "    hls_pred = hls_model.predict(np.expand_dims(data, axis=0))\n",
    "    hls_pred_all.append(hls_pred)\n",
    "    hls_pred = hls_pred.reshape(64, 64, 20)\n",
    "    hls_pred_classes = np.argmax(hls_pred, axis=-1)\n",
    "    hls_pred_classes_all.append(hls_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_pred_classes_all_np =  np.stack(hls_pred_classes_all, axis=0)\n",
    "hls_pred_all_np =  np.stack(hls_pred_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd293512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission CSV\n",
    "import pandas as pd\n",
    "\n",
    "num_samples = len(x_test)\n",
    "\n",
    "hls_pred_classes_all_np_flat = hls_pred_classes_all_np.reshape(num_samples, -1)\n",
    "\n",
    "submission_df = pd.DataFrame(\n",
    "    hls_pred_classes_all_np_flat,\n",
    "    columns=[f\"label{i}\" for i in range(64*64)]\n",
    ")\n",
    "submission_df.insert(0, \"id\", np.arange(num_samples))\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"submission.csv saved with shape: {submission_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a878279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save testbench files for hls project\n",
    "batch_num=5\n",
    "x_test_batch = x_test[:batch_num]  # Use only a subset for testbench\n",
    "hls_pred_all_np_batch = hls_pred_all_np[:batch_num]\n",
    "\n",
    "#write x_test to tb_input_features.dat\n",
    "INPUT_FILE = hls_path + '/tb_data/tb_input_features.dat'\n",
    "np.savetxt(INPUT_FILE, x_test_batch.reshape(x_test_batch.shape[0], -1), delimiter=' ', fmt='%f')\n",
    "\n",
    "#write x_test to tb_input_features.dat\n",
    "OUTPUT_FILE = hls_path + '/tb_data/tb_output_predictions.dat'\n",
    "np.savetxt(OUTPUT_FILE, hls_pred_all_np_batch.reshape(hls_pred_all_np_batch.shape[0], -1), delimiter=' ', fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031917e",
   "metadata": {},
   "source": [
    "# ZIP the HLS project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r {hls_path}.zip {hls_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
